{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7404d5bb-1207-4c9c-80dd-2b69a30bff7d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3b54cdd-c600-404d-b538-8019917d0905",
     "showTitle": false,
     "title": "--i18n-f71eff64-cf6e-469a-ab37-a297936c4980"
    }
   },
   "source": [
    "\n",
    "\n",
    "# Active Users Lab\n",
    "Plot daily active users and average active users by day of week.\n",
    "1. Extract timestamp and date of events\n",
    "2. Get daily active users\n",
    "3. Get average number of active users by day of week\n",
    "4. Sort day of week in correct order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9a18684-0043-4fbf-a0d4-09c93a0873b9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nPython interpreter will be restarted.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting the learning environment:\n| No action taken\n\nSkipping install of existing datasets to \"dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03\"\n\nValidating the locally installed datasets:\n| listing local files...(3 seconds)\n| validation completed...(3 seconds total)\n\nCreating & using the schema \"muaazkhurshid_q1yg_da_asp\" in the catalog \"spark_catalog\"...(0 seconds)\n\nPredefined tables in \"muaazkhurshid_q1yg_da_asp\":\n| -none-\n\nPredefined paths variables:\n| DA.paths.working_dir: dbfs:/mnt/dbacademy-users/muaazkhurshid@uni-koblenz.de/apache-spark-programming-with-databricks\n| DA.paths.user_db:     dbfs:/mnt/dbacademy-users/muaazkhurshid@uni-koblenz.de/apache-spark-programming-with-databricks/database.db\n| DA.paths.datasets:    dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03\n| DA.paths.checkpoints: dbfs:/mnt/dbacademy-users/muaazkhurshid@uni-koblenz.de/apache-spark-programming-with-databricks/_checkpoints\n\nSetup completed (6 seconds)\n\nPredefined tables in \"muaazkhurshid_q1yg_da_asp\":\n| -none-\n\nPredefined paths variables:\n| DA.paths.working_dir: dbfs:/mnt/dbacademy-users/muaazkhurshid@uni-koblenz.de/apache-spark-programming-with-databricks\n| DA.paths.user_db:     dbfs:/mnt/dbacademy-users/muaazkhurshid@uni-koblenz.de/apache-spark-programming-with-databricks/database.db\n| DA.paths.datasets:    dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03\n| DA.paths.checkpoints: dbfs:/mnt/dbacademy-users/muaazkhurshid@uni-koblenz.de/apache-spark-programming-with-databricks/_checkpoints\n| DA.paths.sales:       dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/ecommerce/sales/sales.delta\n| DA.paths.users:       dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/ecommerce/users/users.delta\n| DA.paths.events:      dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/ecommerce/events/events.delta\n| DA.paths.products:    dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/products/products.delta\n\nSetup completed (6 seconds)\n"
     ]
    }
   ],
   "source": [
    "%run ../Includes/Classroom-Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4bb7eace-5457-4268-87c5-9895a61b7863",
     "showTitle": false,
     "title": "--i18n-3a6a78da-1772-441e-b73a-eff2e82561bb"
    }
   },
   "source": [
    "\n",
    "\n",
    "### Setup\n",
    "Run the cell below to create the starting DataFrame of user IDs and timestamps of events logged on the BedBricks website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8ea5f0a-f15f-49bd-9270-da52593df2c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = (spark\n",
    "      .read\n",
    "      .format(\"delta\")\n",
    "      .load(DA.paths.events)\n",
    "      .select(\"user_id\", col(\"event_timestamp\").alias(\"ts\"))\n",
    "     )\n",
    "\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9b7c0ee-b6f0-4f8f-b1dc-068a1b6a69a8",
     "showTitle": false,
     "title": "--i18n-7fa26321-781b-4633-bce4-5b86082adbcc"
    }
   },
   "source": [
    "\n",
    "\n",
    "### 1. Extract timestamp and date of events\n",
    "- Convert **`ts`** from microseconds to seconds by dividing by 1 million and cast to timestamp\n",
    "- Add **`date`** column by converting **`ts`** to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d233b5b6-31cb-4030-b33c-2b9f5f58d18d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import TimestampType, DateType\n",
    "datetime_df = (df.withColumn(\"ts\", (col(\"ts\")/1e6).cast(TimestampType()))\n",
    "               .withColumn(\"date\", (col(\"ts\")).cast(DateType()))\n",
    ")\n",
    "# display(datetime_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1f97ce8-66ba-45e5-b014-b9c4cd5a6b52",
     "showTitle": false,
     "title": "--i18n-50e248b0-9067-4ec0-b633-1862739315f1"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "**1.1: CHECK YOUR WORK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31789894-86b1-45e2-93e0-a19b480473fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test pass\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import DateType, StringType, StructField, StructType, TimestampType\n",
    "\n",
    "expected1a = StructType([StructField(\"user_id\", StringType(), True),\n",
    "                         StructField(\"ts\", TimestampType(), True),\n",
    "                         StructField(\"date\", DateType(), True)])\n",
    "\n",
    "result1a = datetime_df.schema\n",
    "\n",
    "assert expected1a == result1a, \"datetime_df does not have the expected schema\"\n",
    "print(\"All test pass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24450c84-cd22-4ea6-8aeb-88ad9cffa20f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test pass\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "expected1b = datetime.date(2020, 6, 19)\n",
    "result1b = datetime_df.sort(\"date\").first().date\n",
    "\n",
    "assert expected1b == result1b, \"datetime_df does not have the expected date values\"\n",
    "print(\"All test pass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ca173fe-029d-4822-b858-a447992a00ed",
     "showTitle": false,
     "title": "--i18n-cffda679-267e-4934-9316-f33d68f1fff6"
    }
   },
   "source": [
    "\n",
    "\n",
    "### 2. Get daily active users\n",
    "- Group by date\n",
    "- Aggregate approximate count of distinct **`user_id`** and alias to \"active_users\"\n",
    "  - Recall built-in function to get **approximate count distinct** (also recall:  approximate count distinct is different than count distinct!)\n",
    "- Sort by date\n",
    "- Plot as line graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebf9feff-90e3-4dc1-a40f-e83ab337dc3b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>date</th><th>active_users</th></tr></thead><tbody><tr><td>2020-06-19</td><td>251573</td></tr><tr><td>2020-06-20</td><td>357215</td></tr><tr><td>2020-06-21</td><td>305055</td></tr><tr><td>2020-06-22</td><td>239094</td></tr><tr><td>2020-06-23</td><td>243117</td></tr><tr><td>2020-06-24</td><td>235205</td></tr><tr><td>2020-06-25</td><td>246548</td></tr><tr><td>2020-06-26</td><td>245022</td></tr><tr><td>2020-06-27</td><td>301330</td></tr><tr><td>2020-06-28</td><td>260756</td></tr><tr><td>2020-06-29</td><td>237297</td></tr><tr><td>2020-06-30</td><td>278768</td></tr><tr><td>2020-07-01</td><td>219223</td></tr><tr><td>2020-07-02</td><td>282692</td></tr><tr><td>2020-07-03</td><td>244947</td></tr><tr><td>2020-07-04</td><td>176901</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2020-06-19",
         251573
        ],
        [
         "2020-06-20",
         357215
        ],
        [
         "2020-06-21",
         305055
        ],
        [
         "2020-06-22",
         239094
        ],
        [
         "2020-06-23",
         243117
        ],
        [
         "2020-06-24",
         235205
        ],
        [
         "2020-06-25",
         246548
        ],
        [
         "2020-06-26",
         245022
        ],
        [
         "2020-06-27",
         301330
        ],
        [
         "2020-06-28",
         260756
        ],
        [
         "2020-06-29",
         237297
        ],
        [
         "2020-06-30",
         278768
        ],
        [
         "2020-07-01",
         219223
        ],
        [
         "2020-07-02",
         282692
        ],
        [
         "2020-07-03",
         244947
        ],
        [
         "2020-07-04",
         176901
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "date",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "active_users",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO\n",
    "from pyspark.sql.functions import approx_count_distinct\n",
    "active_users_df = (datetime_df.groupBy(\"date\").agg(approx_count_distinct(\"user_id\").alias(\"active_users\")).sort(\"date\")\n",
    ")\n",
    "display(active_users_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9cc6434-fd30-48df-8397-ba2c8fc04608",
     "showTitle": false,
     "title": "--i18n-168eed92-68bf-4966-98b6-f92bc44fbe67"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "**2.1: CHECK YOUR WORK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "657bbf6a-9ac0-4e23-9368-a30f76c90e98",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test pass\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import LongType\n",
    "\n",
    "expected2a = StructType([StructField(\"date\", DateType(), True),\n",
    "                         StructField(\"active_users\", LongType(), False)])\n",
    "\n",
    "result2a = active_users_df.schema\n",
    "\n",
    "assert expected2a == result2a, \"active_users_df does not have the expected schema\"\n",
    "print(\"All test pass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34647460-2365-40cd-9cf7-55a47002c1de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test pass\n"
     ]
    }
   ],
   "source": [
    "expected2b = [(datetime.date(2020, 6, 19), 251573), (datetime.date(2020, 6, 20), 357215), (datetime.date(2020, 6, 21), 305055), (datetime.date(2020, 6, 22), 239094), (datetime.date(2020, 6, 23), 243117)]\n",
    "\n",
    "result2b = [(row.date, row.active_users) for row in active_users_df.orderBy(\"date\").take(5)]\n",
    "\n",
    "assert expected2b == result2b, \"active_users_df does not have the expected values\"\n",
    "print(\"All test pass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a569e003-1d99-46cd-b4bd-616cfbd8eb12",
     "showTitle": false,
     "title": "--i18n-ac71e88e-aa3d-4032-8741-876f0d8ff8da"
    }
   },
   "source": [
    "\n",
    "\n",
    "### 3. Get average number of active users by day of week\n",
    "- Add **`day`** column by extracting day of week from **`date`** using a datetime pattern string - the expected output here will be a day name, not a number (e.g. **`Mon`**, not **`1`**)\n",
    "- Group by **`day`**\n",
    "- Aggregate average of **`active_users`** and alias to \"avg_users\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05d54b6d-ee55-492d-8ea9-e7d4dd4c7192",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>day</th><th>avg_users</th></tr></thead><tbody><tr><td>Sun</td><td>282905.5</td></tr><tr><td>Mon</td><td>238195.5</td></tr><tr><td>Thu</td><td>264620.0</td></tr><tr><td>Sat</td><td>278482.0</td></tr><tr><td>Wed</td><td>227214.0</td></tr><tr><td>Fri</td><td>247180.66666666666</td></tr><tr><td>Tue</td><td>260942.5</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Sun",
         282905.5
        ],
        [
         "Mon",
         238195.5
        ],
        [
         "Thu",
         264620.0
        ],
        [
         "Sat",
         278482.0
        ],
        [
         "Wed",
         227214.0
        ],
        [
         "Fri",
         247180.66666666666
        ],
        [
         "Tue",
         260942.5
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "day",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "avg_users",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO\n",
    "from pyspark.sql.functions import date_format, avg\n",
    "active_dow_df = (active_users_df.withColumn(\"day\", date_format(\"date\", \"E\"))\n",
    "                 .groupBy(\"day\").agg(avg(\"active_users\").alias(\"avg_users\"))\n",
    ")\n",
    "display(active_dow_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d603045b-96c2-4139-a261-c5bb5435d665",
     "showTitle": false,
     "title": "--i18n-889c1b5c-f870-45d0-8cc0-5e1c58f6640e"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "**3.1: CHECK YOUR WORK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87df8dd9-99c9-460d-b55d-22aabfdee709",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test pass\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "expected3a = StructType([StructField(\"day\", StringType(), True),\n",
    "                         StructField(\"avg_users\", DoubleType(), True)])\n",
    "\n",
    "result3a = active_dow_df.schema\n",
    "\n",
    "assert expected3a == result3a, \"active_dow_df does not have the expected schema\"\n",
    "print(\"All test pass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c54c43f-c586-4e4e-a859-8f91e75a1bbb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test pass\n"
     ]
    }
   ],
   "source": [
    "expected3b = [(\"Fri\", 247180.66666666666), (\"Mon\", 238195.5), (\"Sat\", 278482.0), (\"Sun\", 282905.5), (\"Thu\", 264620.0), (\"Tue\", 260942.5), (\"Wed\", 227214.0)]\n",
    "\n",
    "result3b = [(row.day, row.avg_users) for row in active_dow_df.sort(\"day\").collect()]\n",
    "\n",
    "assert expected3b == result3b, \"active_dow_df does not have the expected values\"\n",
    "print(\"All test pass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf3ed947-2308-436a-afb4-81cf97b48147",
     "showTitle": false,
     "title": "--i18n-f4b41974-87d7-47fe-81f8-93fd5c99fbe1"
    }
   },
   "source": [
    "\n",
    "\n",
    "### Clean up classroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2428bdd-7987-42e1-98ed-01a7adb8bf97",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting the learning environment:\n| dropping the schema \"muaazkhurshid_q1yg_da_asp\"...(1 seconds)\n| removing the working directory \"dbfs:/mnt/dbacademy-users/muaazkhurshid@uni-koblenz.de/apache-spark-programming-with-databricks\"...(0 seconds)\n\nValidating the locally installed datasets:\n| listing local files...(3 seconds)\n| validation completed...(3 seconds total)\n"
     ]
    }
   ],
   "source": [
    "DA.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a41fb27c-661d-4a68-bcdf-c3bdd68787d9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "&copy; 2023 Databricks, Inc. All rights reserved.<br/>\n",
    "Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
    "<br/>\n",
    "<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "ASP 3.2L - Active Users Lab",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
