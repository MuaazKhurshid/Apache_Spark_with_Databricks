{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38595546-5625-4735-9729-e8ece3398564",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9905116-bd55-47d8-aa63-329eaa6662f1",
     "showTitle": false,
     "title": "--i18n-07f4fc7f-00c7-45f0-a3da-d8317e646802"
    }
   },
   "source": [
    "\n",
    "\n",
    "# Explore Datasets Lab\n",
    "\n",
    "We will use tools introduced in this lesson to explore the datasets used in this course.\n",
    "\n",
    "### BedBricks Case Study\n",
    "This course uses a case study that explores clickstream data for the online mattress retailer, BedBricks.  \n",
    "You are an analyst at BedBricks working with the following datasets: **`events`**, **`sales`**, **`users`**, and **`products`**.\n",
    "\n",
    "##### Tasks\n",
    "1. View data files in DBFS using magic commands\n",
    "1. View data files in DBFS using dbutils\n",
    "1. Create tables from files in DBFS\n",
    "1. Execute SQL to answer questions on BedBricks datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba42b774-6fce-4b5e-8da1-e4c583539be8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nPython interpreter will be restarted.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting the learning environment:\n| No action taken\n\nInstalling datasets:\n| from \"wasbs://courseware@dbacademy.blob.core.windows.net/apache-spark-programming-with-databricks/v03\"\n| to \"dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03\"\n|\n| NOTE: The datasets that we are installing are located in Washington, USA - depending on the\n|       region that your workspace is in, this operation can take as little as 2 min and\n|       upwards to 5 min, but this is a one-time operation.\n| \n| copying 1/3: ecommerce...(147 seconds)\n| copying 2/3: people...(1 seconds)\n| copying 3/3: products...(5 seconds)\n|\n| completed datasets installation successfully...(153 seconds)\n\nValidating the locally installed datasets:\n| listing local files...(5 seconds)\n| validation completed...(5 seconds total)\n\nCreating & using the schema \"muaazkhurshid_q1yg_da_asp\" in the catalog \"spark_catalog\"...(0 seconds)\n\nPredefined tables in \"muaazkhurshid_q1yg_da_asp\":\n| -none-\n\nPredefined paths variables:\n| DA.paths.working_dir: dbfs:/mnt/dbacademy-users/muaazkhurshid@uni-koblenz.de/apache-spark-programming-with-databricks\n| DA.paths.user_db:     dbfs:/mnt/dbacademy-users/muaazkhurshid@uni-koblenz.de/apache-spark-programming-with-databricks/database.db\n| DA.paths.datasets:    dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03\n| DA.paths.checkpoints: dbfs:/mnt/dbacademy-users/muaazkhurshid@uni-koblenz.de/apache-spark-programming-with-databricks/_checkpoints\n\nSetup completed (180 seconds)\n\nPredefined tables in \"muaazkhurshid_q1yg_da_asp\":\n| -none-\n\nPredefined paths variables:\n| DA.paths.working_dir: dbfs:/mnt/dbacademy-users/muaazkhurshid@uni-koblenz.de/apache-spark-programming-with-databricks\n| DA.paths.user_db:     dbfs:/mnt/dbacademy-users/muaazkhurshid@uni-koblenz.de/apache-spark-programming-with-databricks/database.db\n| DA.paths.datasets:    dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03\n| DA.paths.checkpoints: dbfs:/mnt/dbacademy-users/muaazkhurshid@uni-koblenz.de/apache-spark-programming-with-databricks/_checkpoints\n| DA.paths.sales:       dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/ecommerce/sales/sales.delta\n| DA.paths.users:       dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/ecommerce/users/users.delta\n| DA.paths.events:      dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/ecommerce/events/events.delta\n| DA.paths.products:    dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/products/products.delta\n\nSetup completed (181 seconds)\n"
     ]
    }
   ],
   "source": [
    "%run ../Includes/Classroom-Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f292a87-4327-4300-87fc-75fb610a2667",
     "showTitle": false,
     "title": "--i18n-418554c8-03e8-461f-9724-6314c7acd53e"
    }
   },
   "source": [
    "\n",
    "\n",
    "### 1. List files in DBFS using magic commands\n",
    "Use a magic command to display files located in the DBFS directory: **`dbfs:/mnt/dbacademy-users/`**\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/icon_hint_32.png\" alt=\"Hint\"> You should see several user directories including your own. Depending on your permissions, you may see only your user directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c66a4781-c53c-4835-902c-dd2b57dab016",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/mnt/dbacademy-users/muaazkhurshid@uni-koblenz.de/</td><td>muaazkhurshid@uni-koblenz.de/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/dbacademy-users/temp/</td><td>temp/</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/mnt/dbacademy-users/muaazkhurshid@uni-koblenz.de/",
         "muaazkhurshid@uni-koblenz.de/",
         0,
         0
        ],
        [
         "dbfs:/mnt/dbacademy-users/temp/",
         "temp/",
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs ls dbfs:/mnt/dbacademy-users/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c3a9a66-ac8e-4c96-9495-9b4ee648c45e",
     "showTitle": false,
     "title": "--i18n-8ad4d9c6-75e8-4f02-9962-20045fc781be"
    }
   },
   "source": [
    "\n",
    "\n",
    "### 2. List files in DBFS using dbutils\n",
    "- Use **`dbutils`** to get the files at the directory above and assign it to the variable **`files`**\n",
    "- Use the Databricks display() function to display the contents in **`files`**\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/icon_hint_32.png\" alt=\"Hint\"> Just as before, you should see several user directories including your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bce01a4e-9e1d-483c-9286-538cafdbe92d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/mnt/dbacademy-users/muaazkhurshid@uni-koblenz.de/</td><td>muaazkhurshid@uni-koblenz.de/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/dbacademy-users/temp/</td><td>temp/</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/mnt/dbacademy-users/muaazkhurshid@uni-koblenz.de/",
         "muaazkhurshid@uni-koblenz.de/",
         0,
         0
        ],
        [
         "dbfs:/mnt/dbacademy-users/temp/",
         "temp/",
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO\n",
    "files = dbutils.fs.ls('dbfs:/mnt/dbacademy-users/')\n",
    "display(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03b0b22c-08fe-4338-b807-6be80c14ae09",
     "showTitle": false,
     "title": "--i18n-28ce7cfb-287a-47a9-8974-c0a99bedcf2e"
    }
   },
   "source": [
    "\n",
    "\n",
    "### 3. Create tables below from files in DBFS\n",
    "- Create the **`users`** table using the spark-context variable **`DA.paths.users`**\n",
    "- Create the **`sales`** table using the spark-context variable **`DA.paths.sales`**\n",
    "- Create the **`products`** table using the spark-context variable **`DA.paths.products`**\n",
    "- Create the **`events`** table using the spark-context variable **`DA.paths.events`**\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/icon_hint_32.png\"> Hint: We created the **`events`** table in the previous notebook but in a different database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f742fc6-a9b6-429c-ba9b-70530471b445",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Setting configs for all the files. i.e users, sales, products, events\n",
    "spark.conf.set(\"paths.users\", DA.paths.users)\n",
    "spark.conf.set(\"paths.sales\", DA.paths.sales)\n",
    "spark.conf.set(\"paths.products\", DA.paths.products)\n",
    "spark.conf.set(\"paths.events\", DA.paths.events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5813a81-9ed4-4df5-a2b4-ced642c4a833",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "\u001B[0;32m<command-3196930024501700>\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n",
       "\u001B[1;32m      8\u001B[0m     \u001B[0mdisplay\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m      9\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m---> 10\u001B[0;31m   \u001B[0m_sqldf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m____databricks_percent_sql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\u001B[1;32m     11\u001B[0m \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m     12\u001B[0m   \u001B[0;32mdel\u001B[0m \u001B[0m____databricks_percent_sql\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;32m<command-3196930024501700>\u001B[0m in \u001B[0;36m____databricks_percent_sql\u001B[0;34m()\u001B[0m\n",
       "\u001B[1;32m      4\u001B[0m     \u001B[0mspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbase64\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstandard_b64decode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Q1JFQVRFIFRBQkxFIElGIE5PVCBFWElTVFMgdXNlcnMKVVNJTkcgREVMVEEKT1BUSU9OUyAocGF0aD0iJHtwYXRocy51c2Vyc30iKQ==\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m      5\u001B[0m     \u001B[0mspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbase64\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstandard_b64decode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Q1JFQVRFIFRBQkxFIElGIE5PVCBFWElTVFMgc2FsZXMKVVNJTkcgREVMVEEKT1BUSU9OUyAocGF0aD0iJHtwYXRocy5zYWxlc30iKQ==\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m----> 6\u001B[0;31m     \u001B[0mspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbase64\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstandard_b64decode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Q1JFQVRFIFRBQkxFIHByb2R1Y3RzClVTSU5HIERFTFRBCk9QVElPTlMgKHBhdGg9IiR7cGF0aHMucHJvZHVjdHN9Iik=\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\u001B[1;32m      7\u001B[0m     \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbase64\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstandard_b64decode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Q1JFQVRFIFRBQkxFIGV2ZW50cwpVU0lORyBERUxUQQpPUFRJT05TIChwYXRoPSIke3BhdGhzLmV2ZW50c30iKQ==\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m      8\u001B[0m     \u001B[0mdisplay\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     46\u001B[0m             \u001B[0mstart\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mperf_counter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m     47\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m---> 48\u001B[0;31m                 \u001B[0mres\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\u001B[1;32m     49\u001B[0m                 logger.log_success(\n",
       "\u001B[1;32m     50\u001B[0m                     \u001B[0mmodule_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclass_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunction_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mperf_counter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mstart\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msignature\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;32m/databricks/spark/python/pyspark/sql/session.py\u001B[0m in \u001B[0;36msql\u001B[0;34m(self, sqlQuery, **kwargs)\u001B[0m\n",
       "\u001B[1;32m   1117\u001B[0m             \u001B[0msqlQuery\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mformatter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msqlQuery\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m   1118\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m-> 1119\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jsparkSession\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msqlQuery\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\u001B[1;32m   1120\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m   1121\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1319\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m   1320\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m-> 1321\u001B[0;31m         return_value = get_return_value(\n",
       "\u001B[0m\u001B[1;32m   1322\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n",
       "\u001B[1;32m   1323\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;32m/databricks/spark/python/pyspark/sql/utils.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    200\u001B[0m                 \u001B[0;31m# Hide where the exception came from that shows a non-Pythonic\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    201\u001B[0m                 \u001B[0;31m# JVM exception message.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m--> 202\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mconverted\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\u001B[1;32m    203\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    204\u001B[0m                 \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: Table muaazkhurshid_q1yg_da_asp.products already exists"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n\u001B[0;32m<command-3196930024501700>\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[0mdisplay\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m   \u001B[0m_sqldf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m____databricks_percent_sql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     11\u001B[0m \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m   \u001B[0;32mdel\u001B[0m \u001B[0m____databricks_percent_sql\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m<command-3196930024501700>\u001B[0m in \u001B[0;36m____databricks_percent_sql\u001B[0;34m()\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0mspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbase64\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstandard_b64decode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Q1JFQVRFIFRBQkxFIElGIE5PVCBFWElTVFMgdXNlcnMKVVNJTkcgREVMVEEKT1BUSU9OUyAocGF0aD0iJHtwYXRocy51c2Vyc30iKQ==\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbase64\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstandard_b64decode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Q1JFQVRFIFRBQkxFIElGIE5PVCBFWElTVFMgc2FsZXMKVVNJTkcgREVMVEEKT1BUSU9OUyAocGF0aD0iJHtwYXRocy5zYWxlc30iKQ==\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m     \u001B[0mspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbase64\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstandard_b64decode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Q1JFQVRFIFRBQkxFIHByb2R1Y3RzClVTSU5HIERFTFRBCk9QVElPTlMgKHBhdGg9IiR7cGF0aHMucHJvZHVjdHN9Iik=\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m     \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbase64\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstandard_b64decode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Q1JFQVRFIFRBQkxFIGV2ZW50cwpVU0lORyBERUxUQQpPUFRJT05TIChwYXRoPSIke3BhdGhzLmV2ZW50c30iKQ==\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[0mdisplay\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m             \u001B[0mstart\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mperf_counter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     47\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 48\u001B[0;31m                 \u001B[0mres\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     49\u001B[0m                 logger.log_success(\n\u001B[1;32m     50\u001B[0m                     \u001B[0mmodule_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclass_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunction_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mperf_counter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mstart\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msignature\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/session.py\u001B[0m in \u001B[0;36msql\u001B[0;34m(self, sqlQuery, **kwargs)\u001B[0m\n\u001B[1;32m   1117\u001B[0m             \u001B[0msqlQuery\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mformatter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msqlQuery\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1118\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1119\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jsparkSession\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msqlQuery\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1120\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1121\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1319\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1320\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1321\u001B[0;31m         return_value = get_return_value(\n\u001B[0m\u001B[1;32m   1322\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001B[1;32m   1323\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/utils.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    200\u001B[0m                 \u001B[0;31m# Hide where the exception came from that shows a non-Pythonic\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    201\u001B[0m                 \u001B[0;31m# JVM exception message.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 202\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mconverted\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    203\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    204\u001B[0m                 \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mAnalysisException\u001B[0m: Table muaazkhurshid_q1yg_da_asp.products already exists",
       "errorSummary": "<span class='ansi-red-fg'>AnalysisException</span>: Table muaazkhurshid_q1yg_da_asp.products already exists",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS users\n",
    "USING DELTA\n",
    "OPTIONS (path=\"${paths.users}\");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS sales\n",
    "USING DELTA\n",
    "OPTIONS (path=\"${paths.sales}\");\n",
    "\n",
    "CREATE TABLE products\n",
    "USING DELTA\n",
    "OPTIONS (path=\"${paths.products}\");\n",
    "\n",
    "CREATE TABLE events\n",
    "USING DELTA\n",
    "OPTIONS (path=\"${paths.events}\");\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0cc80389-64ae-41b1-a68c-82a6941c0439",
     "showTitle": false,
     "title": "--i18n-fbbfc7b2-2a54-4b81-a17f-77de6aec377f"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "Use the data tab of the workspace UI to confirm your tables were created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b923a1b4-1e22-45a1-941b-9f68516553f2",
     "showTitle": false,
     "title": "--i18n-55e585c9-b437-44c6-ac03-f11c7cd9c38b"
    }
   },
   "source": [
    "\n",
    "\n",
    "### 4. Execute SQL to explore BedBricks datasets\n",
    "Run SQL queries on the **`products`**, **`sales`**, and **`events`** tables to answer the following questions. \n",
    "- What products are available for purchase at BedBricks?\n",
    "- What is the average purchase revenue for a transaction at BedBricks?\n",
    "- What types of events are recorded on the BedBricks website?\n",
    "\n",
    "The schema of the relevant dataset is provided for each question in the cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0763187-deb7-4d30-9be2-0120dc2ac5e9",
     "showTitle": false,
     "title": "--i18n-60b7be2f-7f11-4e34-bf18-57e39d69f6ca"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "#### 4.1: What products are available for purchase at BedBricks?\n",
    "\n",
    "The **`products`** dataset contains the ID, name, and price of products on the BedBricks retail site.\n",
    "\n",
    "| field | type | description\n",
    "| --- | --- | --- |\n",
    "| item_id | string | unique item identifier |\n",
    "| name | string | item name in plain text |\n",
    "| price | double | price of item |\n",
    "\n",
    "Execute a SQL query that selects all from the **`products`** table. \n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/icon_hint_32.png\" alt=\"Hint\"> You should see 12 products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fd312af-b482-4c8e-b7d5-c77e434962e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>item_id</th><th>name</th><th>price</th></tr></thead><tbody><tr><td>M_PREM_Q</td><td>Premium Queen Mattress</td><td>1795.0</td></tr><tr><td>M_STAN_F</td><td>Standard Full Mattress</td><td>945.0</td></tr><tr><td>M_PREM_F</td><td>Premium Full Mattress</td><td>1695.0</td></tr><tr><td>M_PREM_T</td><td>Premium Twin Mattress</td><td>1095.0</td></tr><tr><td>M_PREM_K</td><td>Premium King Mattress</td><td>1995.0</td></tr><tr><td>P_DOWN_S</td><td>Standard Down Pillow</td><td>119.0</td></tr><tr><td>M_STAN_Q</td><td>Standard Queen Mattress</td><td>1045.0</td></tr><tr><td>M_STAN_K</td><td>Standard King Mattress</td><td>1195.0</td></tr><tr><td>M_STAN_T</td><td>Standard Twin Mattress</td><td>595.0</td></tr><tr><td>P_FOAM_S</td><td>Standard Foam Pillow</td><td>59.0</td></tr><tr><td>P_FOAM_K</td><td>King Foam Pillow</td><td>79.0</td></tr><tr><td>P_DOWN_K</td><td>King Down Pillow</td><td>159.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "M_PREM_Q",
         "Premium Queen Mattress",
         1795.0
        ],
        [
         "M_STAN_F",
         "Standard Full Mattress",
         945.0
        ],
        [
         "M_PREM_F",
         "Premium Full Mattress",
         1695.0
        ],
        [
         "M_PREM_T",
         "Premium Twin Mattress",
         1095.0
        ],
        [
         "M_PREM_K",
         "Premium King Mattress",
         1995.0
        ],
        [
         "P_DOWN_S",
         "Standard Down Pillow",
         119.0
        ],
        [
         "M_STAN_Q",
         "Standard Queen Mattress",
         1045.0
        ],
        [
         "M_STAN_K",
         "Standard King Mattress",
         1195.0
        ],
        [
         "M_STAN_T",
         "Standard Twin Mattress",
         595.0
        ],
        [
         "P_FOAM_S",
         "Standard Foam Pillow",
         59.0
        ],
        [
         "P_FOAM_K",
         "King Foam Pillow",
         79.0
        ],
        [
         "P_DOWN_K",
         "King Down Pillow",
         159.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "item_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "price",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT \n",
    "pdcts.item_id\n",
    ", pdcts.name\n",
    ", pdcts.price\n",
    "FROM muaazkhurshid_q1yg_da_asp.products pdcts;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7688cc2a-714e-4f13-b3a3-f9bb7650641c",
     "showTitle": false,
     "title": "--i18n-535df503-7397-4c6b-a89b-39b310f09ff7"
    }
   },
   "source": [
    "\n",
    "\n",
    "#### 4.2: What is the average purchase revenue for a transaction at BedBricks?\n",
    "\n",
    "The **`sales`** dataset contains order information representing successfully processed sales.  \n",
    "Most fields correspond directly with fields from the clickstream data associated with a sale finalization event.\n",
    "\n",
    "| field | type | description|\n",
    "| --- | --- | --- |\n",
    "| order_id | long | unique identifier |\n",
    "| email | string | the email address to which sales configuration was sent |\n",
    "| transaction_timestamp | long | timestamp at which the order was processed, recorded in milliseconds since epoch |\n",
    "| total_item_quantity | long | number of individual items in the order |\n",
    "| purchase_revenue_in_usd | double | total revenue from order |\n",
    "| unique_items | long | number of unique products in the order |\n",
    "| items | array | provided as a list of JSON data, which is interpreted by Spark as an array of structs |\n",
    "\n",
    "Execute a SQL query that computes the average **`purchase_revenue_in_usd`** from the **`sales`** table.\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/icon_hint_32.png\" alt=\"Hint\"> The result should be **`1042.79`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11320653-d6ec-4e82-89d8-933e08cae0a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>avg_purchase_revenue_in_usd</th></tr></thead><tbody><tr><td>1042.7902657223433</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1042.7902657223433
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "avg_purchase_revenue_in_usd",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT\n",
    "AVG(purchase_revenue_in_usd) as avg_purchase_revenue_in_usd\n",
    "FROM muaazkhurshid_q1yg_da_asp.sales;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "649edc22-158a-4327-a889-db3b18a63fcd",
     "showTitle": false,
     "title": "--i18n-1646e571-2039-4f10-b407-5139b89199ef"
    }
   },
   "source": [
    "\n",
    "\n",
    "#### 4.3: What types of events are recorded on the BedBricks website?\n",
    "\n",
    "The **`events`** dataset contains two weeks worth of parsed JSON records, created by consuming updates to an operational database.  \n",
    "Records are received whenever: (1) a new user visits the site, (2) a user provides their email for the first time.\n",
    "\n",
    "| field | type | description|\n",
    "| --- | --- | --- |\n",
    "| device | string | operating system of the user device |\n",
    "| user_id | string | unique identifier for user/session |\n",
    "| user_first_touch_timestamp | long | first time the user was seen in microseconds since epoch |\n",
    "| traffic_source | string | referral source |\n",
    "| geo (city, state) | struct | city and state information derived from IP address |\n",
    "| event_timestamp | long | event time recorded as microseconds since epoch |\n",
    "| event_previous_timestamp | long | time of previous event in microseconds since epoch |\n",
    "| event_name | string | name of events as registered in clickstream tracker |\n",
    "| items (item_id, item_name, price_in_usd, quantity, item_revenue in usd, coupon)| array | an array of structs for each unique item in the userâ€™s cart |\n",
    "| ecommerce (total_item_quantity, unique_items, purchase_revenue_in_usd)  |  struct  | purchase data (this field is only non-null in those events that correspond to a sales finalization) |\n",
    "\n",
    "Execute a SQL query that selects distinct values in **`event_name`** from the **`events`** table\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/icon_hint_32.png\" alt=\"Hint\"> You should see 23 distinct **`event_name`** values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5117d20-d09d-421b-9e11-91c83dffc653",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>cnt_dstnct_events</th></tr></thead><tbody><tr><td>23</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         23
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "cnt_dstnct_events",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT \n",
    "COUNT(DISTINCT event_name) as cnt_dstnct_events\n",
    "FROM muaazkhurshid_q1yg_da_asp.events;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0eba9b5c-47a1-49c9-b75b-85f14df33cf4",
     "showTitle": false,
     "title": "--i18n-d68908dd-7069-4671-850a-db458003aa53"
    }
   },
   "source": [
    "\n",
    "\n",
    "### Clean up classroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2985a60a-fae5-49a6-80c9-2a8baf5ddda6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting the learning environment:\n| dropping the schema \"muaazkhurshid_q1yg_da_asp\"...(3 seconds)\n| removing the working directory \"dbfs:/mnt/dbacademy-users/muaazkhurshid@uni-koblenz.de/apache-spark-programming-with-databricks\"...(0 seconds)\n\nValidating the locally installed datasets:\n| listing local files...(4 seconds)\n| validation completed...(4 seconds total)\n"
     ]
    }
   ],
   "source": [
    "DA.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef6c659f-53cb-4042-a13d-ba9e6996f500",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "&copy; 2023 Databricks, Inc. All rights reserved.<br/>\n",
    "Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
    "<br/>\n",
    "<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3196930024501708,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "ASP 1.1L - Explore Datasets Lab",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
